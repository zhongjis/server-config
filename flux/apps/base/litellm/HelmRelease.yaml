---
# yaml-language-server: $schema=https://raw.githubusercontent.com/fluxcd-community/flux2-schemas/refs/heads/main/all.json
apiVersion: helm.toolkit.fluxcd.io/v2
kind: HelmRelease
metadata:
  name: litellm
  namespace: litellm
spec:
  interval: 30m
  chartRef:
    kind: OCIRepository
    name: litellm
    namespace: litellm
  dependsOn:
    - name: litellm-cnpg-cluster
  valuesFrom:
    # externalPostgresql
    - kind: Secret
      name: litellm-cnpg-cluster-app
      valuesKey: uri
      targetPath: db.url
  values:
    replicaCount: 2
    numWorkers: 2

    db:
      useExisting: true
      deployStandalone: false
      secret:
        name: litellm-cnpg-cluster-app
        usernameKey: username
        passwordKey: password

    masterkeySecretName: "litellm-secrets-flux"
    masterkeySecretKey: "masterKey"

    proxyConfigMap:
      create: true
      key: "config.yaml"

    proxy_config:
      litellm_settings:
        callbacks: ["langfuse_otel"]
      model_list:
        - model_name: gpt-3.5-turbo
          litellm_params:
            model: gpt-3.5-turbo
            api_key: os.environ/OPENAI_API_KEY

    environmentSecrets:
      - litellm-secrets-env-flux

    ingress:
      enabled: true
      annotations:
        gethomepage.dev/description: A service that lets you access multiple language models (LLMs) using the OpenAI input/output format.
        gethomepage.dev/enabled: "true"
        gethomepage.dev/group: Backend
        gethomepage.dev/name: LiteLLM
        kubernetes.io/tls-acme: "true"
      className: nginx
      hosts:
        - host: litellm.zshen.me
          paths:
            - path: /
              pathType: ImplementationSpecific
      tls:
        - secretName: litellm-tls
          hosts:
            - litellm.zshen.me

    serviceMonitor:
      enabled: true
